# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TRDLoz7nAyOa9OmGphA-Mvp6_cqB7NX3
"""
# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TRDLoz7nAyOa9OmGphA-Mvp6_cqB7NX3
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os

AUTOTUNE = tf.data.AUTOTUNE

img_size = (128, 128)     # smaller size = less RAM
batch_size = 16           # safe for Colab
epochs = 10

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets list

!kaggle datasets download -d multi-crop-plant-leaf-disease-detection-dataset

!unzip -q multi-crop-plant-leaf-disease-detection-dataset.zip -d .

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os

import os
import shutil

data_dir = "/content/Data"

for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)
    if len(os.listdir(class_path)) == 0:
        shutil.rmtree(class_path)
        print(f"Removed empty class: {cls}")

import numpy as np

# Count images per class again
class_counts = {}
for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)
    count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])
    class_counts[cls] = count

max_count = max(class_counts.values())
print("Maximum images in any class:", max_count)

for cls, count in class_counts.items():
    class_path = os.path.join(data_dir, cls)
    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]

    if len(images) == 0:
        print(f"Skipping empty class: {cls}")
        continue  # skip augmentation for empty class

    while len(images) < max_count:
        img_name = np.random.choice(images)
        img_path = os.path.join(class_path, img_name)

        img = load_img(img_path, target_size=img_size)
        img = img_to_array(img)
        img = tf.expand_dims(img, 0)

        aug_img = augmentor(img)
        aug_img = aug_img.numpy()[0]

        new_name = f"aug_{len(images)}.jpg"
        save_img(os.path.join(class_path, new_name), aug_img)
        images.append(new_name)

AUTOTUNE = tf.data.AUTOTUNE

img_size = (128, 128)     # smaller size = less RAM
batch_size = 16           # safe for Colab
epochs = 10

data_dir = "/content/Data"   # CHANGE THIS PATH

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

class_names = train_ds.class_names
num_classes = len(class_names)

print("Classes:", class_names)
print("Number of classes:", num_classes)

train_ds = train_ds.shuffle(1000).prefetch(AUTOTUNE)
val_ds   = val_ds.prefetch(AUTOTUNE)

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

model = tf.keras.Sequential([
    data_augmentation,
    tf.keras.layers.Rescaling(1./255),

    tf.keras.layers.Conv2D(32, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(64, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(128, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=4

)

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="Train")
plt.plot(history.history["val_accuracy"], label="Val")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="Train")
plt.plot(history.history["val_loss"], label="Val")
plt.title("Loss")
plt.legend()

plt.show()

model.save("/content/image_model.keras")

loaded_model = tf.keras.models.load_model("/content/image_model.keras")

from tensorflow.keras.preprocessing import image

img_path = "/content/aug_0_4.jpg"   # change this

img = image.load_img(img_path, target_size=img_size)
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array / 255.0

predictions = loaded_model.predict(img_array)
predicted_class = class_names[np.argmax(predictions)]

print("Predicted Class:", predicted_class)

import os

# Path to your dataset folder
data_dir = "/content/Data"   # Change this to your folder path

# Loop through each class folder
for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)

    # Only count files (images)
    num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])

    print(f"Class '{cls}' has {num_images} images")


import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os

AUTOTUNE = tf.data.AUTOTUNE

img_size = (128, 128)     # smaller size = less RAM
batch_size = 16           # safe for Colab
epochs = 10

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets list

!kaggle datasets download -d multi-crop-plant-leaf-disease-detection-dataset

!unzip -q multi-crop-plant-leaf-disease-detection-dataset.zip -d .

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os

import os
import shutil

data_dir = "/content/Data"

for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)
    if len(os.listdir(class_path)) == 0:
        shutil.rmtree(class_path)
        print(f"Removed empty class: {cls}")

import numpy as np

# Count images per class again
class_counts = {}
for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)
    count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])
    class_counts[cls] = count

max_count = max(class_counts.values())
print("Maximum images in any class:", max_count)

for cls, count in class_counts.items():
    class_path = os.path.join(data_dir, cls)
    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]

    if len(images) == 0:
        print(f"Skipping empty class: {cls}")
        continue  # skip augmentation for empty class

    while len(images) < max_count:
        img_name = np.random.choice(images)
        img_path = os.path.join(class_path, img_name)

        img = load_img(img_path, target_size=img_size)
        img = img_to_array(img)
        img = tf.expand_dims(img, 0)

        aug_img = augmentor(img)
        aug_img = aug_img.numpy()[0]

        new_name = f"aug_{len(images)}.jpg"
        save_img(os.path.join(class_path, new_name), aug_img)
        images.append(new_name)

AUTOTUNE = tf.data.AUTOTUNE

img_size = (128, 128)     # smaller size = less RAM
batch_size = 16           # safe for Colab
epochs = 10

data_dir = "/content/Data"   # CHANGE THIS PATH

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

class_names = train_ds.class_names
num_classes = len(class_names)

print("Classes:", class_names)
print("Number of classes:", num_classes)

train_ds = train_ds.shuffle(1000).prefetch(AUTOTUNE)
val_ds   = val_ds.prefetch(AUTOTUNE)

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

model = tf.keras.Sequential([
    data_augmentation,
    tf.keras.layers.Rescaling(1./255),

    tf.keras.layers.Conv2D(32, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(64, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(128, 3, activation="relu"),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=4

)

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="Train")
plt.plot(history.history["val_accuracy"], label="Val")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="Train")
plt.plot(history.history["val_loss"], label="Val")
plt.title("Loss")
plt.legend()

plt.show()

model.save("/content/image_model.keras")

loaded_model = tf.keras.models.load_model("/content/image_model.keras")

from tensorflow.keras.preprocessing import image

img_path = "/content/aug_0_4.jpg"   # change this

img = image.load_img(img_path, target_size=img_size)
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array / 255.0

predictions = loaded_model.predict(img_array)
predicted_class = class_names[np.argmax(predictions)]

print("Predicted Class:", predicted_class)

import os

# Path to your dataset folder
data_dir = "/content/Data"   # Change this to your folder path

# Loop through each class folder
for cls in os.listdir(data_dir):
    class_path = os.path.join(data_dir, cls)

    # Only count files (images)
    num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])

    print(f"Class '{cls}' has {num_images} images")

